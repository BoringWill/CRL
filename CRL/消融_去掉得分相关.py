import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
import pygame
from collections import deque
from slime_env import SlimeSelfPlayEnv
from concurrent.futures import ProcessPoolExecutor, as_completed

# --- æ ¸å¿ƒé…ç½® ---
CONFIG = {
    "adaptive_model_path": "æœ€å¼ºæ¨¡å‹é›†/best.pth",
    "opponents_dir": "æœ€å¼ºæ¨¡å‹é›†",
    "device": torch.device("cpu"),
    # åŸºç¡€æ¸©åº¦ï¼šå½“æ¯”åˆ†æŒå¹³æ—¶ï¼Œä¿æŒåœ¨è¿™ä¸ªæ¸©åº¦ï¼ˆ1.0ä»£è¡¨æœ‰ä¸€å®šçš„éšæœºæ€§ï¼Œ0.1ä»£è¡¨æœ€å¼ºï¼‰
    "init_temp": 1.0,
    "min_temp": 0.1,
    "max_temp": 10.0,
    # æƒ¯æ€§ç³»æ•°ï¼šæ•°å€¼è¶Šå°ï¼Œæ¸©åº¦å˜åŒ–è¶Šå¹³æ»‘ï¼Œé˜²æ­¢æ¸©åº¦å‰§çƒˆè·³å˜
    "inertia": 0.1,
    "max_workers": 10,
    # åˆ†å·®æ•æ„Ÿåº¦ï¼šæ¯è½å1åˆ†ï¼Œæ¸©åº¦é™ä½å¤šå°‘ï¼ˆå˜å¾—æ›´å¼ºï¼‰
    "score_sensitivity": 2.0
}


# --- 1. é€»è¾‘ç»„ä»¶ (ä¿®æ”¹éƒ¨åˆ†ï¼šçº¯åˆ†å·®é©±åŠ¨) ---
class ScoreOnlyDifficultyManager:
    def __init__(self):
        self.current_temp = CONFIG["init_temp"]

    def update(self, p1_score, p2_score):
        """
        ä»…æ ¹æ®åˆ†å·®è°ƒæ•´æ¸©åº¦ï¼š
        - P1 (å›ºå®šå¯¹æ‰‹) åˆ†æ•°é«˜ -> P2 (è‡ªé€‚åº”) è½å -> æ¸©åº¦é™ä½ (å˜å¼º)
        - P2 åˆ†æ•°é«˜ -> é¢†å…ˆ -> æ¸©åº¦å‡é«˜ (å˜å¼±/å¨±ä¹)
        """
        score_diff = p1_score - p2_score  # æ­£æ•°ä»£è¡¨P2è½åï¼Œè´Ÿæ•°ä»£è¡¨P2é¢†å…ˆ

        # ç›®æ ‡æ¸©åº¦è®¡ç®—å…¬å¼ï¼šåŸºå‡†æ¸©åº¦ - (åˆ†å·® * æ•æ„Ÿåº¦)
        # ä¾‹å¦‚ï¼šåŸºå‡†1.0ï¼Œè½å2åˆ†(diff=2) -> target = 1.0 - 4.0 = -3.0 -> clipåˆ° 0.1
        # ä¾‹å¦‚ï¼šåŸºå‡†1.0ï¼Œé¢†å…ˆ2åˆ†(diff=-2) -> target = 1.0 + 4.0 = 5.0
        target_temp = CONFIG["init_temp"] - (score_diff * CONFIG["score_sensitivity"])

        # é™åˆ¶èŒƒå›´
        target_temp = np.clip(target_temp, CONFIG["min_temp"], CONFIG["max_temp"])

        # æƒ¯æ€§å¹³æ»‘ç§»åŠ¨
        diff = target_temp - self.current_temp
        # å¦‚æœæ˜¯é™æ¸©ï¼ˆå˜å¼ºï¼‰ï¼Œååº”å¿«ä¸€ç‚¹ï¼›å¦‚æœæ˜¯å‡æ¸©ï¼ˆå˜å¼±ï¼‰ï¼Œååº”æ…¢ä¸€ç‚¹
        move_speed = CONFIG["inertia"] * (1.5 if diff < 0 else 0.5)

        self.current_temp += diff * move_speed
        self.current_temp = np.clip(self.current_temp, CONFIG["min_temp"], CONFIG["max_temp"])

        return self.current_temp, score_diff


class Agent(nn.Module):
    def __init__(self):
        super(Agent, self).__init__()
        # Critic ä»ç„¶ä¿ç•™ç»“æ„ä»¥ä¾¿åŠ è½½æƒé‡ï¼Œä½†ä¸å‚ä¸é€»è¾‘è®¡ç®—
        self.critic = nn.Sequential(nn.Linear(52, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 1))
        self.actor = nn.Sequential(nn.Linear(52, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU(), nn.Linear(128, 4))

    def get_action(self, obs, temp):
        with torch.no_grad():
            t_obs = torch.as_tensor(obs, dtype=torch.float32).unsqueeze(0)
            logits = self.actor(t_obs)
            probs = F.softmax(logits / temp, dim=-1)
            return torch.distributions.Categorical(probs).sample().item()


def load_weights(model, path):
    if not os.path.exists(path): return False
    ckpt = torch.load(path, map_location="cpu")
    model.load_state_dict(ckpt["model_state_dict"] if "model_state_dict" in ckpt else ckpt, strict=True)
    return True


# --- 2. æ ¸å¿ƒå¯¹æˆ˜é€»è¾‘ (ä¿®æ”¹éƒ¨åˆ†ï¼šç§»é™¤Valueä¼ å‚) ---
def play_one_match(opp_name, render=False):
    render_mode = "human" if render else None
    env = SlimeSelfPlayEnv(render_mode=render_mode)

    agent_adaptive = Agent()
    load_weights(agent_adaptive, CONFIG["adaptive_model_path"])

    agent_fixed = Agent()
    opp_path = os.path.join(CONFIG["opponents_dir"], opp_name)
    load_weights(agent_fixed, opp_path)

    # ä½¿ç”¨æ–°çš„åˆ†å·®ç®¡ç†å™¨
    diff_manager = ScoreOnlyDifficultyManager()

    # å‡†å¤‡å­—ä½“æ¸²æŸ“
    font = None
    if render:
        try:
            font = pygame.font.SysFont("Arial", 20, bold=True)
        except:
            font = pygame.font.Font(None, 24)

    p1_dq, p2_dq = deque(maxlen=4), deque(maxlen=4)
    raw_obs_p1, _ = env.reset()
    raw_obs_p2 = env._get_obs(2)
    for _ in range(4): p1_dq.append(raw_obs_p1); p2_dq.append(raw_obs_p2)

    done = False
    while not done:
        if render:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    pygame.quit()
                    return None

        obs_p1 = np.concatenate(list(p1_dq))
        obs_p2 = np.concatenate(list(p2_dq))

        # --- ä¿®æ”¹ï¼šä¸å†è®¡ç®—Valueï¼Œåªæ ¹æ®æ¯”åˆ†æ›´æ–°æ¸©åº¦ ---
        curr_temp, score_diff = diff_manager.update(env.p1_score, env.p2_score)

        # é‡‡æ ·åŠ¨ä½œ
        a1 = agent_fixed.get_action(obs_p1, 0.01)  # å¯¹æ‰‹ä¿æŒæœ€å¼ºçŠ¶æ€
        a2 = agent_adaptive.get_action(obs_p2, curr_temp)

        n_p1, n_p2, _, term, trunc, _ = env.step((a1, a2))
        p1_dq.append(n_p1);
        p2_dq.append(n_p2)

        if render:
            env.render()
            try:
                screen = pygame.display.get_surface()
                if screen is not None and font is not None:
                    # é¢œè‰²æç¤ºï¼šæ¸©åº¦ä½ï¼ˆå¼ºï¼‰æ˜¾ç¤ºçº¢è‰²ï¼Œæ¸©åº¦é«˜ï¼ˆå¼±ï¼‰æ˜¾ç¤ºç»¿è‰²
                    temp_color = (255, 50, 50) if curr_temp < 0.5 else (50, 255, 50)
                    texts = [
                        (f"Temp: {curr_temp:.2f}", temp_color),
                        (f"Score Diff: {score_diff}", (255, 255, 255)),
                        (f"Opponent: {opp_name}", (255, 255, 0))
                    ]
                    for i, (text, color) in enumerate(texts):
                        txt_surf = font.render(text, True, color)
                        screen.blit(txt_surf, (10, 10 + i * 25))
                    pygame.display.flip()
            except:
                pass
            time.sleep(0.015)

        if term or trunc:
            done = True

    result = {
        "opponent": opp_name,
        "p1_score": env.p1_score,
        "p2_score": env.p2_score,
        "win": env.p2_score > env.p1_score
    }
    env.close()
    return result


# --- 3. æ§åˆ¶å™¨ ---
def run_fast_tournament():
    opp_files = [f for f in os.listdir(CONFIG["opponents_dir"]) if f.endswith(".pth")]
    opp_files.sort()

    print(f"ğŸ§ª å¼€å§‹æ¶ˆèå®éªŒ (ä»…åˆ†æ•°é©±åŠ¨) | å¹¶è¡Œæ•°: {CONFIG['max_workers']} | å¯¹æ‰‹æ€»æ•°: {len(opp_files)}")
    print("=" * 60)

    all_results = []
    # ç§»é™¤äº† Manager å’Œ shared_stateï¼Œå› ä¸ºä¸å†éœ€è¦ç»Ÿè®¡å…¨å±€Valueåˆ†å¸ƒ
    with ProcessPoolExecutor(max_workers=CONFIG["max_workers"]) as executor:
        futures = {executor.submit(play_one_match, name, False): name for name in opp_files}
        for future in as_completed(futures):
            res = future.result()
            if res:
                all_results.append(res)
                status = "ğŸ† WIN" if res['win'] else "âŒ LOSS"
                print(f"[{status}] {res['opponent'].ljust(25)} | P1: {res['p1_score']} vs P2: {res['p2_score']}")

    print("\n" + "=" * 60)
    print("ğŸ“Š æ¶ˆèå®éªŒç»Ÿè®¡")
    print("-" * 60)
    wins = sum(1 for r in all_results if r['win'])
    total = len(all_results)
    if total > 0:
        print(f"æ€»åœºæ¬¡: {total} | èƒœç‡: {wins / total:.2%} | èƒœ: {wins} / è´Ÿ: {total - wins}")
    print("=" * 60)


if __name__ == "__main__":
    print("--- ğŸ”¬ æ¶ˆèå®éªŒæ¨¡å¼ï¼šä»…ä¿ç•™åˆ†æ•°å½±å“æ¸©åº¦ ---")
    mode = input("1. å¿«é€Ÿæ¨¡å¼ (å¹¶å‘+æ— æ¸²æŸ“)\n2. è§‚æˆ˜æ¨¡å¼ (å•çº¿ç¨‹+æœ‰æ¸²æŸ“)\nè¯·é€‰æ‹©: ")

    if mode == "1":
        run_fast_tournament()
    else:
        pygame.init()
        if not pygame.font.get_init():
            pygame.font.init()

        opp_files = [f for f in os.listdir(CONFIG["opponents_dir"]) if f.endswith(".pth")]
        opp_files.sort()

        print("\nğŸ“º è¿›å…¥è§‚æˆ˜æ¨¡å¼...")
        for f in opp_files:
            if f == os.path.basename(CONFIG["adaptive_model_path"]): continue

            print(f"ğŸ® æ­£åœ¨å¯¹æˆ˜: {f}")
            res = play_one_match(f, render=True)

            if res is None: break

            status = "ğŸ† WIN" if res['win'] else "âŒ LOSS"
            print(f"[{status}] æˆ˜å±€ç»“æŸ | P1: {res['p1_score']} vs P2: {res['p2_score']}")
            print("-" * 40)

        pygame.quit()